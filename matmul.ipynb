{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE HUNT FOR THE BETTER DEEP LEARNING LIBRARY IN JULIA BEGINS...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our search to make a good deeplearning library in Julia. This search is inspired by Jeremy Howard's course \"Deep Learning from foundations\" on FastAI. Our primary motive is to understand nuts and bolts of neural networks. So, lets dive in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. THE BETTER MATRIX MULTIPLICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Multiplication is the backbone of all neural networks. Basically every layer of neural network is a column of weight matrix. So the entire forward pass will be a matrix multiplication of weight matrix with the input matrix. So we will emulate a MNIST dataset. It'll be basically *28x28* matrix. So the input matrix is with *n* rows and *784* columns. And we have to predict one out of *10*  categories. So the weight matrix will be *784x10* matrix so that the output will be a matrix of dimensions *nx10*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(5, 784);\n",
    "y = rand(784,10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we need a metric to compare our different methods of matrix multiply. So lets import the \"BenchmarkTools\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also lets create tests for our desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_for_size (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_for_size(prod)\n",
    "    @assert size(prod) == (5,10)\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: The old school for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its said that Julia is as fast as C language. Which means the for loops will run blazingly fast. Let's see how it fares..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmul_for_loop (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function matmul_for_loop(a,b)\n",
    "    ar, ac = size(a)\n",
    "    br, bc = size(b)\n",
    "    c = zeros(ar,bc)\n",
    "    @assert ac == br\n",
    "    for i in 1:ar\n",
    "        for j in 1:bc\n",
    "            for k in 1:ac\n",
    "                c[i,j] += a[i,k] * b[k,j];\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return c\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's see how fast it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  113.670 μs (1 allocation: 496 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime matmul_for_loop(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woahhhhh.... 113 microseconds. Its way faster than Julia's counterpart Python. But I guess we can do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_size(matmul_for_loop(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But our test passed..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take advantages of 4 cores of my cpu and Julia's parallel processing capabilities. First lets create a julia kernel with 4 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Installing Julia 4 Threads kernelspec in /home/vishal/.local/share/jupyter/kernels/julia-4-threads-1.5\n",
      "└ @ IJulia /home/vishal/.julia/packages/IJulia/DrVMH/deps/kspec.jl:78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/home/vishal/.local/share/jupyter/kernels/julia-4-threads-1.5\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using IJulia\n",
    "IJulia.installkernel(\"Julia 4 Threads\", env=Dict(\n",
    "    \"JULIA_NUM_THREADS\" => \"4\",\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets change our kernel to 4 threaded kernel. This can be done by Kernel tab -->  Change Kernel and changing the kernel to \"Julia 4 Threads (version no.)\". Don't forget to initialise the vital stuff after changing the kernel. Now lets slightly modify our matmul function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmul_for_loop_threads (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function matmul_for_loop_threads(a,b)\n",
    "    ar, ac = size(a)\n",
    "    br, bc = size(b)\n",
    "    c = zeros(ar,bc)\n",
    "    @assert ac == br\n",
    "    Threads.@threads for i in 1:ar\n",
    "        Threads.@threads for j in 1:bc\n",
    "            Threads.@threads for k in 1:ac\n",
    "                c[i,j] += a[i,k] * b[k,j];\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_size(matmul_for_loop_threads(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  76.333 μs (131 allocations: 7.77 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime matmul_for_loop_threads(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used lot of allocations and memory but we have done almost twice faster. Kudos...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Julia's usual matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good thing is that julia follows  Matlab in most of ways. One of it is it can implicitly multiply matrices like multiplying any other datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_size(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.497 μs (1 allocation: 496 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime x*y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damnnnn.... This is the best we can get. The raw power of julia. For comparison, the best deeplearning library in python, pytorch takes 18 µs to do this exact same matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Using the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already we have a huge margin against the vendor libraries in python. Lets push a little bit further. Lets do it on our GPU. For that let's use ArrayFire. There are many libraries to do GPU computation in Julia. Infact the last thing Julia needs is another GPU Library. But I choose Arrayfire amongst the libraries like CUDA.jl which are written in pure Julia, because ArrayFire supports all the hardware accelerators including Nvidia GPUs, AMD GPUs, Intel Xeon processors, etc. So its chosen for its superior versatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayFire v3.7.2 (CUDA, 64-bit Linux, build 218dd2c)\n",
      "Platform: CUDA Runtime 10.0, Driver: 440.100\n",
      "[0] GeForce 920MX, 2005 MB, CUDA Compute 5.0\n"
     ]
    }
   ],
   "source": [
    "using ArrayFire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = AFArray(x);\n",
    "Y = AFArray(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_size(X*Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10.062 μs (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AFArray: 5×10 Array{Float64,2}:\n",
       " 189.546  198.151  194.221  189.911  …  189.055  195.472  185.416  179.904\n",
       " 192.635  196.665  191.585  191.174     187.576  195.448  185.041  184.126\n",
       " 201.885  205.919  199.898  204.712     193.873  209.095  197.891  197.193\n",
       " 192.72   198.777  193.842  192.935     186.979  197.593  187.286  190.028\n",
       " 197.884  199.994  197.255  198.984     188.164  203.601  190.319  189.015"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime X*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 4 Threads 1.5.0",
   "language": "julia",
   "name": "julia-4-threads-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
